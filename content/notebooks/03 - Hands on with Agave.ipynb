{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Setting Stuff Up</h2>\n",
    "\n",
    "Here we import some packages that we'll need in various places. We'll also load all the variables we set in config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/agave\n",
      "Collecting setvar\n",
      "  Downloading setvar-1.0.6.tar.gz\n",
      "Building wheels for collected packages: setvar\n",
      "  Running setup.py bdist_wheel for setvar ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/66/d8/dc/afb8ee5142a6a23753b5f1ac067e42b310c450e89f45cc0ecf\n",
      "Successfully built setvar\n",
      "Installing collected packages: setvar\n",
      "Successfully installed setvar-1.0.6\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ~/agave\n",
    "\n",
    "%cd ~/agave\n",
    "\n",
    "!pip3 install --upgrade setvar\n",
    "\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from setvar import *\n",
    "from time import sleep\n",
    "\n",
    "# This cell enables inline plotting in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "loadvar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running locally using Docker Compose, you will need to pull the ip and port of your reverse tunnel from the sandbox. Uncomment the following command, and enter below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tenant configuration  \n",
    "\n",
    "If you are running against a privately hosted Agave tenant, you need to configure the tutorial to run against your tenant. You can do that by setting the `AGAVE_TENANTS_API_BASEURL` and `AGAVE_TENANT_ID` environment variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you specified the correct address to your Tenants API, you should be able to discover the tenants available for you through the CLI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0magave.prod\r\n",
      "araport.org\r\n",
      "designsafe\r\n",
      "iplantc.org\r\n",
      "irec\r\n",
      "irmacs\r\n",
      "sd2e\r\n",
      "sgci\r\n",
      "tacc.prod\r\n",
      "vdjserver.org\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!tenants-list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the tenant you would like to use by setting the `AGAVE_TENANT` environment variable. You may select either the name of the tenant, or the You may use the value of _0_ to select the default tenant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0mYou are now configured to interact with the APIs at https://public.agaveapi.co/\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!tenants-init -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create the Client</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this next step we delete the client if it exists. Chances are, yours doesn't yet. We put this command here in case, for some reason, you want to re-create your client later on. If you delete the client you intend to create before you create it, no harm is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0mSuccessfully deleted client funwave-tvd-sc17-stevenrbrandt\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!clients-delete -u \"$AGAVE_USERNAME\" -p \"$AGAVE_PASSWORD\" $AGAVE_APP_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step we create the client. Clients provide a way of encapsulating resources connected to a single project. Through the client, you will receive a token which you can use to run most of the Agave commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0m\u001b[1;0mSuccessfully created client funwave-tvd-sc17-stevenrbrandt\r\n",
      "key: lcA43NPdaG15zhcoPeH1g8AhZfga \r\n",
      "secret: Mqok7TdnpvgR7fQCFDlSWXUKAHoa\u001b[0m\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!clients-create -u $AGAVE_USERNAME -p \"$AGAVE_PASSWD\" -N $AGAVE_APP_NAME -S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the token for your client. You will, from this point on, use this token to run the remainder of the Agave commands in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0mToken for agave.prod:stevenrbrandt successfully refreshed and cached for 14400 seconds\r\n",
      "851bce22897cbd9a79334a5e9c1e5b2\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!auth-tokens-create -u $AGAVE_USERNAME -p \"$AGAVE_PASSWD\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FOLLOWING ALONG AT HOME  \n",
    "\n",
    "If you are following along at home using the docker-compose stack, you will need to run the following cell to get the hsotname and port of your tcp tunnel so Agave can contact your system without a public IP address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file `ngrok_host.txt'\n",
      "Reading file `ngrok_port.txt'\n",
      "Reading file `ngrok_host.txt'\n",
      "Reading file `ngrok_port.txt'\n"
     ]
    }
   ],
   "source": [
    "if os.environ.get('USE_TUNNEL') == 'True': \n",
    "    # fetch the hostname and port of the reverse tunnel running in the sandbox \n",
    "    # so Agave can connect to our local sandbox\n",
    "    !echo $(ssh -q -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null sandbox 'curl -s  http://localhost:4040/api/tunnels | jq -r '.tunnels[0].public_url'') > ngrok_url.txt  \n",
    "    !cat ngrok_url.txt | sed 's|^tcp://||' | sed -r 's#(.*):(.*)#\\1#' > ngrok_host.txt\n",
    "    !cat ngrok_url.txt | sed 's|^tcp://||' | sed -r 's#(.*):(.*)#\\2#' > ngrok_port.txt\n",
    "\n",
    "    # set the environment variables otherwise set when running in a training cluster\n",
    "    os.environ['MACHINE_IP'] = readfile('ngrok_host.txt').strip()\n",
    "    os.environ['MACHINE_PORT'] = readfile('ngrok_port.txt').strip()\n",
    "    os.environ['AGAVE_SYSTEM_HOST'] = readfile('ngrok_host.txt').strip()\n",
    "    os.environ['AGAVE_SYSTEM_PORT'] = readfile('ngrok_port.txt').strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Storage Machine   \n",
    "\n",
    "Agave wants to know which place (or places) you want to store the data associated with your jobs. Here, we're going to set that up. Authentication to the storage machine will be through SSH keys. The key and public key files, however, contain newlines. To encode them in Json (the data format used by Agave), we will run the jsonpki command on each file. Next, we will store its contents in the environment for use by setvar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!jsonpki --public ~/.ssh/id_rsa.pub > ~/.ssh/id_rsa.pub.txt\n",
    "!jsonpki --private ~/.ssh/id_rsa > ~/.ssh/id_rsa.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file `/home/jovyan/.ssh/id_rsa.pub.txt'\n",
      "Reading file `/home/jovyan/.ssh/id_rsa.txt'\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"PUB_KEY\"]=readfile(\"${HOME}/.ssh/id_rsa.pub.txt\").strip()\n",
    "os.environ[\"PRIV_KEY\"]=readfile(\"${HOME}/.ssh/id_rsa.txt\").strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this next cell, we create the json file used to describe the storage machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file `nectar-storage-stevenrbrandt.txt'\n"
     ]
    }
   ],
   "source": [
    "writefile(\"${AGAVE_STORAGE_SYSTEM_ID}.txt\",\"\"\"{\n",
    "    \"id\": \"${AGAVE_STORAGE_SYSTEM_ID}\",\n",
    "    \"name\": \"${MACHINE_NAME} storage (${MACHINE_USERNAME})\",\n",
    "    \"description\": \"The ${MACHINE_NAME} computer\",\n",
    "    \"site\": \"${AGAVE_SYSTEM_SITE_DOMAIN}\",\n",
    "    \"type\": \"STORAGE\",\n",
    "    \"storage\": {\n",
    "        \"host\": \"${AGAVE_SYSTEM_HOST}\",\n",
    "        \"port\": ${AGAVE_SYSTEM_PORT},\n",
    "        \"protocol\": \"SFTP\",\n",
    "        \"rootDir\": \"/\",\n",
    "        \"homeDir\": \"${AGAVE_STORAGE_HOME_DIR}\",\n",
    "        \"auth\": {\n",
    "          \"username\" : \"${MACHINE_USERNAME}\",\n",
    "          \"publicKey\" : \"${PUB_KEY}\",\n",
    "          \"privateKey\" : \"${PRIV_KEY}\",\n",
    "          \"type\" : \"SSHKEYS\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we tell Agave about the machine. You can re-run the previous cell and the next one if you want to change the definition of your storage machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0m\u001b[1;0mSuccessfully added system nectar-storage-stevenrbrandt\u001b[0m\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!systems-addupdate -F ${AGAVE_STORAGE_SYSTEM_ID}.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we run the Agave command `files-list`. This provides a check that we've set up the storage machine correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      ".bash_logout\r\n",
      ".bashrc\r\n",
      ".cache\r\n",
      ".docker\r\n"
     ]
    }
   ],
   "source": [
    "!files-list -S ${AGAVE_STORAGE_SYSTEM_ID} ./ | head -5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Setting up the Execution Machine</h2>\n",
    "\n",
    "You may not always wish to store your data on the same machine you run your jobs on. However, in this tutorial, we will assume that you do. The description for the execution machine is much like the storage machine. However, there are a few more pieces of information you'll need to provide. In this example, we are going to call commands directly on the host as opposed to using a batch queue scheduler. It is slightly simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file `nectar-exec-training001.txt'\n"
     ]
    }
   ],
   "source": [
    "# Edit any parts of this file that you know need to be changed for your machine.\n",
    "writefile(\"${AGAVE_EXECUTION_SYSTEM_ID}.txt\",\"\"\"\n",
    "{\n",
    "    \"id\": \"${AGAVE_EXECUTION_SYSTEM_ID}\",\n",
    "    \"name\": \"${MACHINE_NAME} (${MACHINE_USERNAME})\",\n",
    "    \"description\": \"The ${MACHINE_NAME} computer\",\n",
    "    \"site\": \"${AGAVE_SYSTEM_SITE_DOMAIN}\",\n",
    "    \"public\": false,\n",
    "    \"status\": \"UP\",\n",
    "    \"type\": \"EXECUTION\",\n",
    "    \"executionType\": \"CLI\",\n",
    "    \"scheduler\" : \"FORK\",\n",
    "    \"environment\": null,\n",
    "    \"scratchDir\" : \"${SCRATCH_DIR}\",\n",
    "    \"queues\": [\n",
    "        {\n",
    "            \"name\": \"none\",\n",
    "            \"default\": true,\n",
    "            \"maxJobs\": 10,\n",
    "            \"maxUserJobs\": 10,\n",
    "            \"maxNodes\": 6,\n",
    "            \"maxProcessorsPerNode\": 6,\n",
    "            \"minProcessorsPerNode\": 1,\n",
    "            \"maxRequestedTime\": \"00:30:00\"\n",
    "        }\n",
    "    ],\n",
    "    \"login\": {\n",
    "        \"auth\": {\n",
    "          \"username\" : \"${MACHINE_USERNAME}\",\n",
    "          \"publicKey\" : \"${PUB_KEY}\",\n",
    "          \"privateKey\" : \"${PRIV_KEY}\",\n",
    "          \"type\" : \"SSHKEYS\"\n",
    "        },\n",
    "        \"host\": \"${AGAVE_SYSTEM_HOST}\",\n",
    "        \"port\": ${AGAVE_SYSTEM_PORT},\n",
    "        \"protocol\": \"SSH\"\n",
    "    },\n",
    "    \"maxSystemJobs\": 50,\n",
    "    \"maxSystemJobsPerUser\": 50,\n",
    "    \"storage\": {\n",
    "        \"host\": \"${AGAVE_SYSTEM_HOST}\",\n",
    "        \"port\": ${AGAVE_SYSTEM_PORT},\n",
    "        \"protocol\": \"SFTP\",\n",
    "        \"rootDir\": \"/\",\n",
    "        \"homeDir\": \"${AGAVE_STORAGE_HOME_DIR}\",\n",
    "        \"auth\": {\n",
    "          \"username\" : \"${MACHINE_USERNAME}\",\n",
    "          \"publicKey\" : \"${PUB_KEY}\",\n",
    "          \"privateKey\" : \"${PRIV_KEY}\",\n",
    "          \"type\" : \"SSHKEYS\"\n",
    "        }\n",
    "    },\n",
    "    \"workDir\": \"${AGAVE_STORAGE_WORK_DIR}\"\n",
    "}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0m\u001b[1;0mSuccessfully added system nectar-exec-training001\u001b[0m\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!systems-addupdate -F ${AGAVE_EXECUTION_SYSTEM_ID}.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      ".bash_history\r\n",
      ".bash_logout\r\n",
      ".bashrc\r\n",
      ".cache\r\n"
     ]
    }
   ],
   "source": [
    "# Test to see if this worked...\n",
    "!files-list -S ${AGAVE_EXECUTION_SYSTEM_ID} ./ | head -5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create the Application</h3>\n",
    "Agave allows us to describe custom allocations, limiting users to run a specific job. In this case, we're going to create a simple \"fork\" scheduler that just takes the command we want to run as a job parameter. The wrapper file is a shell script we will run on the execution machine. If we were using a scheduler, this would be our batch file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file `fork-wrapper.txt'\n"
     ]
    }
   ],
   "source": [
    "writefile(\"fork-wrapper.txt\",\"\"\"\n",
    "#!/bin/bash\n",
    "\\${command}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Agave commands, we make a directory on the storage server an deploy our wrapper file there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0mSuccessfully created folder agave-deployment\u001b[0m\n",
      "Uploading fork-wrapper.txt...\n",
      "######################################################################## 100.0%\n"
     ]
    }
   ],
   "source": [
    "!files-mkdir -S ${AGAVE_STORAGE_SYSTEM_ID} -N ${AGAVE_APP_DEPLOYMENT_PATH}\n",
    "!files-upload -F fork-wrapper.txt -S ${AGAVE_STORAGE_SYSTEM_ID} ${AGAVE_APP_DEPLOYMENT_PATH}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All agave applications require a test file. The test file is a free form text file which allows you to specify what resources you might need to test your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file `fork-test.txt'\n"
     ]
    }
   ],
   "source": [
    "writefile(\"fork-test.txt\",\"\"\"\n",
    "command=date\n",
    "fork-wrapper.txt\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0mSuccessfully created folder agave-deployment\u001b[0m\n",
      "Uploading fork-test.txt...\n",
      "######################################################################## 100.0%\n"
     ]
    }
   ],
   "source": [
    "!files-mkdir -S ${AGAVE_STORAGE_SYSTEM_ID} -N ${AGAVE_APP_DEPLOYMENT_PATH}\n",
    "!files-upload -F fork-test.txt -S ${AGAVE_STORAGE_SYSTEM_ID} ${AGAVE_APP_DEPLOYMENT_PATH}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like everything else in Agave, we describe our application with Json. We specifiy which machines the application will use, what method it will use for submitting jobs, job parameters and files, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file `fork-app.txt'\n"
     ]
    }
   ],
   "source": [
    "writefile(\"fork-app.txt\",\"\"\"\n",
    "{  \n",
    "   \"name\":\"${AGAVE_USERNAME}-${MACHINE_NAME}-fork\",\n",
    "   \"version\":\"1.0\",\n",
    "   \"label\":\"Runs a command\",\n",
    "   \"shortDescription\":\"Runs a command\",\n",
    "   \"longDescription\":\"\",\n",
    "   \"deploymentSystem\":\"${AGAVE_STORAGE_SYSTEM_ID}\",\n",
    "   \"deploymentPath\":\"${AGAVE_APP_DEPLOYMENT_PATH}\",\n",
    "   \"templatePath\":\"fork-wrapper.txt\",\n",
    "   \"testPath\":\"fork-test.txt\",\n",
    "   \"executionSystem\":\"${AGAVE_EXECUTION_SYSTEM_ID}\",\n",
    "   \"executionType\":\"CLI\",\n",
    "   \"parallelism\":\"SERIAL\",\n",
    "   \"modules\":[],\n",
    "   \"inputs\":[\n",
    "         {   \n",
    "         \"id\":\"datafile\",\n",
    "         \"details\":{  \n",
    "            \"label\":\"Data file\",\n",
    "            \"description\":\"\",\n",
    "            \"argument\":null,\n",
    "            \"showArgument\":false\n",
    "         },\n",
    "         \"value\":{  \n",
    "            \"default\":\"/dev/null\",\n",
    "            \"order\":0,\n",
    "            \"required\":false,\n",
    "            \"validator\":\"\",\n",
    "            \"visible\":true\n",
    "         }\n",
    "      }   \n",
    "   ],\n",
    "   \"parameters\":[{\n",
    "     \"id\" : \"command\",\n",
    "     \"value\" : {\n",
    "       \"visible\":true,\n",
    "       \"required\":true,\n",
    "       \"type\":\"string\",\n",
    "       \"order\":0,\n",
    "       \"enquote\":false,\n",
    "       \"default\":\"/bin/date\",\n",
    "       \"validator\":null\n",
    "     },\n",
    "     \"details\":{\n",
    "         \"label\": \"Command to run\",\n",
    "         \"description\": \"This is the actual command you want to run. ex. df -h -d 1\",\n",
    "         \"argument\": null,\n",
    "         \"showArgument\": false,\n",
    "         \"repeatArgument\": false\n",
    "     },\n",
    "     \"semantics\":{\n",
    "         \"label\": \"Command to run\",\n",
    "         \"description\": \"This is the actual command you want to run. ex. df -h -d 1\",\n",
    "         \"argument\": null,\n",
    "         \"showArgument\": false,\n",
    "         \"repeatArgument\": false\n",
    "     }\n",
    "   }],\n",
    "   \"outputs\":[]\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0m\u001b[1;0mSuccessfully added app training001-training001-fork-1.0\u001b[0m\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!apps-addupdate -F fork-app.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Running Jobs</h2>\n",
    "Now that we have specified our application using Agave, it is time to try running jobs. To start a job we, once again, create a Json file. The Json file describes the app, what resource to run on, as well as how and when to send notifications. Notifications are delivered by callback url. EMAIL is the easiest type to configure, but we show here how to send webhook notifications to the popular [RequestBin](https://requestb.in/). \n",
    "\n",
    "Before we configure our notification, we need to create a requestbin to use. There are convenience commands to interact with requestbin built into the Agave CLI. We will use those to get our URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rburl = !requestbin-create \n",
    "os.environ['REQUESTBIN_URL'] = rburl[0].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a URL to recieve webhooks from our job, Let's look at our job request. The way this job is configured, it will send the requestbin notifications for every job event until the job reaches a terminal state. For a full list of job events, please see http://docs.agaveplatform.org/#job-monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file `job.txt'\n"
     ]
    }
   ],
   "source": [
    "writefile(\"job.txt\",\"\"\"\n",
    " {\n",
    "   \"name\":\"fork-command-1\",\n",
    "   \"appId\": \"${AGAVE_USERNAME}-${MACHINE_NAME}-fork-1.0\",\n",
    "   \"executionSystem\": \"${AGAVE_EXECUTION_SYSTEM_ID}\",\n",
    "   \"archive\": false,\n",
    "   \"notifications\": [\n",
    "    {\n",
    "      \"url\":\"${REQUESTBIN_URL}?event=\\${EVENT}&jobid=\\${JOB_ID}\",\n",
    "      \"event\":\"*\",\n",
    "      \"persistent\":\"true\"\n",
    "    }\n",
    "   ],\n",
    "   \"parameters\": {\n",
    "     \"command\":\"echo hello\"\n",
    "   }\n",
    " }\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the setvar() command can evalute `$()` style bash shell substitutions, we will use it to submit our job. This will capture the output of the submit command, and allow us to parse it for the JOB_ID. We'll use the JOB_ID in several subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT=Successfully submitted job 355644385644899865-242ac11b-0001-007\n",
      "JOB_ID=355644385644899865-242ac11b-0001-007\n"
     ]
    }
   ],
   "source": [
    "setvar(\"\"\"\n",
    "# Capture the output of the job submit command\n",
    "OUTPUT=$(jobs-submit -F job.txt)\n",
    "# Parse out the job id from the output\n",
    "JOB_ID=$(echo $OUTPUT | cut -d' ' -f4)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Job Monitoring and Output</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the job is running, the requestbin you registered will receive webhooks from Agave every time a job event occurs. To monitor this in real time, evaluate the next cell an visit the printed url in your browser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://requestbin.agaveapi.co/s4heb4s4?inspect\n"
     ]
    }
   ],
   "source": [
    "print ('%s?inspect'%os.environ['REQUESTBIN_URL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, you can also monitor the job status by polling. Note that the notifications you receive via email and webhook are less wasteful of resources. However, we show you this for completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAT=PENDING\n",
      "STAT=STAGED\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=FINISHED\n"
     ]
    }
   ],
   "source": [
    "for iter in range(20):\n",
    "    setvar(\"STAT=$(jobs-status $JOB_ID)\")\n",
    "    stat = os.environ[\"STAT\"]\n",
    "    sleep(5.0)\n",
    "    if stat == \"FINISHED\" or stat == \"FAILED\":\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The jobs-history command provides you a record of the steps of what your job did. If your job fails for some reason, this is your best diagnostic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0mJob accepted and queued for submission.\r\n",
      "Skipping staging. No input data associated with this job.\r\n",
      "Preparing job for submission.\r\n",
      "Attempt 1 to submit job\r\n",
      "Fetching app assets from agave://nectar-storage-training001/agave-deployment\r\n",
      "Staging runtime assets to agave://nectar-exec-training001//home/jovyan/training001/job-355644385644899865-242ac11b-0001-007-fork-command-1\r\n",
      "CLI job successfully forked as process id 323\r\n",
      "CLI job successfully forked as process id 323\r\n",
      "Job receieved duplicate RUNNING notification\r\n",
      "Job completed execution\r\n",
      "Job completed. Skipping archiving at user request.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!jobs-history ${JOB_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command shows you the job id's and status of the last 5 jobs you ran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0m355644385644899865-242ac11b-0001-007 FINISHED\r\n",
      "1211262281860583911-242ac11b-0001-007 FINISHED\r\n",
      "116156809723122151-242ac11b-0001-007 FINISHED\r\n",
      "9079267434667577831-242ac11b-0001-007 FINISHED\r\n",
      "7261562989246091751-242ac11b-0001-007 FINISHED\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!jobs-list -l 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next command provides you with a list of all the files generated by your job. You can use it to figure out which files you want to retrieve with jobs-output-get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0m| type | length | name                  |\r\n",
      "| ---- | ------ | ----                  |\r\n",
      "| file | 68     | .agave.archive        |\r\n",
      "| file | 397    | .agave.log            |\r\n",
      "| file | 0      | fork-command-1.err    |\r\n",
      "| file | 2487   | fork-command-1.ipcexe |\r\n",
      "| file | 6      | fork-command-1.out    |\r\n",
      "| file | 4      | fork-command-1.pid    |\r\n",
      "| file | 29     | fork-test.txt         |\r\n",
      "| file | 22     | fork-wrapper.txt      |\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!jobs-output-list --rich --filter=type,length,name ${JOB_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the standard output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################################################## 100.0%\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "!jobs-output-get ${JOB_ID} fork-command-1.out\n",
    "!cat fork-command-1.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the standard error output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n"
     ]
    }
   ],
   "source": [
    "!jobs-output-get ${JOB_ID} fork-command-1.err\n",
    "!cat fork-command-1.err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Automating</h3>\n",
    "Because we're working in Python, we can simply glue the above steps together and create a script to run jobs for us and fetch the standard output. Let's do that next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing runagavecmd.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile runagavecmd.py\n",
    "from setvar import *\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "def runagavecmd(cmd,infile=None):\n",
    "    setvar(\"REMOTE_COMMAND=\"+cmd)\n",
    "    setvar(\"REQUESTBIN_URL=$(requestbin-create)\")\n",
    "    print(\"\")\n",
    "    print(\" ** QUERY STRING FOR REQUESTBIN **\")\n",
    "    print('%s?inspect'%os.environ['REQUESTBIN_URL'])\n",
    "    print(\"\")\n",
    "    # The input file is an optional parameter, both\n",
    "    # to our function and to the Agave application.\n",
    "    if infile == None:\n",
    "        setvar(\"INPUTS={}\")\n",
    "    else:\n",
    "        setvar('INPUTS={\"datafile\":\"'+infile+'\"}')\n",
    "    setvar(\"JOB_FILE=job-remote-$PID.txt\")\n",
    "    # Create the Json for the job file.\n",
    "    writefile(\"$JOB_FILE\",\"\"\"\n",
    " {\n",
    "   \"name\":\"fork-command-1\",\n",
    "   \"appId\": \"${AGAVE_USERNAME}-${MACHINE_NAME}-fork-1.0\",\n",
    "   \"executionSystem\": \"${AGAVE_EXECUTION_SYSTEM_ID}\",\n",
    "   \"archive\": false,\n",
    "   \"notifications\": [\n",
    "    {\n",
    "      \"url\":\"${REQUESTBIN_URL}?event=\\${EVENT}&jobid=\\${JOB_ID}\",\n",
    "      \"event\":\"*\",\n",
    "      \"persistent\":\"true\"\n",
    "    }\n",
    "   ],\n",
    "   \"parameters\": {\n",
    "     \"command\":\"${REMOTE_COMMAND}\"\n",
    "   },\n",
    "   \"inputs\":${INPUTS}\n",
    " }\"\"\")\n",
    "    # Run the job and capture the output.\n",
    "    setvar(\"\"\"\n",
    "# Capture the output of the job submit command\n",
    "OUTPUT=$(jobs-submit -F $JOB_FILE)\n",
    "# Parse out the job id from the output\n",
    "JOB_ID=$(echo $OUTPUT | cut -d' ' -f4)\n",
    "\"\"\")\n",
    "    # Poll and wait for the job to finish.\n",
    "    for iter in range(80): # Excessively generous\n",
    "        setvar(\"STAT=$(jobs-status $JOB_ID)\")\n",
    "        stat = os.environ[\"STAT\"]\n",
    "        sleep(5.0)\n",
    "        if stat == \"FINISHED\" or stat == \"FAILED\":\n",
    "            break\n",
    "    # Fetch the job output from the remote machine\n",
    "    setvar(\"CMD=jobs-output-get ${JOB_ID} fork-command-1.out\")\n",
    "    os.system(os.environ[\"CMD\"])\n",
    "    print(\"All done! Output follows.\")\n",
    "    # Load the output into memory\n",
    "    output=readfile(\"fork-command-1.out\")\n",
    "    print(\"=\" * 70)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'runagavecmd' from '/home/jovyan/agave/runagavecmd.py'>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import runagavecmd as r\n",
    "import imp\n",
    "imp.reload(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOTE_COMMAND=lscpu\n",
      "REQUESTBIN_URL=https://requestbin.agaveapi.co/18ja0091\n",
      "\n",
      " ** QUERY STRING FOR REQUESTBIN **\n",
      "https://requestbin.agaveapi.co/18ja0091?inspect\n",
      "\n",
      "INPUTS={}\n",
      "JOB_FILE=job-remote-180.txt\n",
      "Writing file `job-remote-180.txt'\n",
      "OUTPUT=Successfully submitted job 6071406585651392025-242ac11b-0001-007\n",
      "JOB_ID=6071406585651392025-242ac11b-0001-007\n",
      "STAT=PENDING\n",
      "STAT=PENDING\n",
      "STAT=STAGED\n",
      "STAT=STAGED\n",
      "STAT=STAGED\n",
      "STAT=SUBMITTING\n",
      "STAT=SUBMITTING\n",
      "STAT=RUNNING\n",
      "STAT=FINISHED\n",
      "CMD=jobs-output-get 6071406585651392025-242ac11b-0001-007 fork-command-1.out\n",
      "All done! Output follows.\n",
      "Reading file `fork-command-1.out'\n",
      "======================================================================\n",
      "Architecture:          x86_64\n",
      "CPU op-mode(s):        32-bit, 64-bit\n",
      "Byte Order:            Little Endian\n",
      "CPU(s):                6\n",
      "On-line CPU(s) list:   0-5\n",
      "Thread(s) per core:    1\n",
      "Core(s) per socket:    1\n",
      "Socket(s):             6\n",
      "NUMA node(s):          1\n",
      "Vendor ID:             GenuineIntel\n",
      "CPU family:            6\n",
      "Model:                 63\n",
      "Model name:            Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz\n",
      "Stepping:              2\n",
      "CPU MHz:               2494.224\n",
      "BogoMIPS:              4988.44\n",
      "Virtualization:        VT-x\n",
      "Hypervisor vendor:     KVM\n",
      "Virtualization type:   full\n",
      "L1d cache:             32K\n",
      "L1i cache:             32K\n",
      "L2 cache:              4096K\n",
      "L3 cache:              16384K\n",
      "NUMA node0 CPU(s):     0-5\n",
      "Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology eagerfpu pni pclmulqdq vmx ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r.runagavecmd(\"lscpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Permissions and Sharing</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the users and the permssions they have to look at the given job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0mtraining001 READ WRITE \u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!jobs-pems-list ${JOB_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0mSuccessfully updated permission for training002\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# now pair off with your neighbor and both of you share your job with them.\n",
    "# For now, just give read access\n",
    "!jobs-pems-update -u training002 -p READ ${JOB_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2134155502143598105-242ac11b-0001-007\n"
     ]
    }
   ],
   "source": [
    "# Now let's see if we can see our neighbor's job\n",
    "# Now let's see if we can see our neighbor's job\n",
    "shared_job = !jobs-search --filter=id -l 1 owner.neq=${AGAVE_USERNAME} \n",
    "os.environ['SHARED_JOB_ID'] = shared_job[0]\n",
    "print(os.environ['SHARED_JOB_ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permissions are just that, permitting someone to do something. You said your neighbor could view your job. Let's see what that means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0m1211262281860583911-242ac11b-0001-007 FINISHED\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# You already searched for the job and found it, so you should be able to lis\n",
    "# an view the details\n",
    "!jobs-list $SHARED_JOB_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0mREAD permission granted to training001\r\n",
      "READ permission granted to ktraxler\r\n",
      "Job completed. Skipping archiving at user request.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# You should also be able to view the history. Here we'll just return the last few \n",
    "# events. Notice the history event showed up history event\n",
    "!jobs-history --limit 3 --order desc $SHARED_JOB_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0m-           training001                 68                   .agave.archive 2017-11-11T19:36:44.000-06:00\r\n",
      "-           training001                399                       .agave.log 2017-11-11T19:36:57.000-06:00\r\n",
      "-           training001                  0               fork-command-1.err 2017-11-11T19:36:55.000-06:00\r\n",
      "-           training001               2486            fork-command-1.ipcexe 2017-11-11T19:36:44.000-06:00\r\n",
      "-           training001               1177               fork-command-1.out 2017-11-11T19:36:57.000-06:00\r\n",
      "-           training001                  4               fork-command-1.pid 2017-11-11T19:36:53.000-06:00\r\n",
      "-           training001                 29                    fork-test.txt 2017-11-11T19:33:08.000-06:00\r\n",
      "-           training001                 22                 fork-wrapper.txt 2017-11-11T19:33:04.000-06:00\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# You can also view their job output\n",
    "!jobs-output-list -L $SHARED_JOB_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mUser does not have permission to view this job\u001b[0m\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# What if we no longer want to see the job. Let's delete it.\n",
    "!jobs-delete $SHARED_JOB_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doah! We can't delete the shared job because we weren't granted write permission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0mSuccessfully updated permission for training002\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Let's grant write access and see what we can do\n",
    "!jobs-pems-update -u training002 -p READ_WRITE ${JOB_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0mSuccessfully deleted job 2134155502143598105-242ac11b-0001-007\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Now let's see if we can delete the shared job\n",
    "!jobs-delete $SHARED_JOB_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mJob is already visible.\u001b[0m\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# Wait, now we don't have anything to work with. \n",
    "# No worries. Agave doens't really delete anything. Your job is still there\n",
    "# We just need to restore it.\n",
    "!jobs-restore $SHARED_JOB_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mPermission denied. You do not have permission to access this app\u001b[0m\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# Now let's try to rerun the job\n",
    "!jobs-resubmit $SHARED_JOB_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nectar-exec-training002', 'training002-training002-fork-1.0']\n"
     ]
    }
   ],
   "source": [
    "# Well, what app did they use in the job?\n",
    "\n",
    "shared_job = !jobs-list -v --filter=executionSystem,appId $SHARED_JOB_ID | jq -r '. | [ .executionSystem , .appId] | .[]'\n",
    "print(shared_job)\n",
    "os.environ['SHARED_JOB_APP'] = shared_job[1]\n",
    "os.environ['SHARED_JOB_SYSTEM'] = shared_job[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0mtraining002 READ WRITE EXECUTE \r\n",
      "ktraxler READ EXECUTE \r\n",
      "training001 READ \u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Hmm, do we have access to the app?\n",
    "! apps-pems-list $SHARED_JOB_APP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0m\u001b[1;0mSuccessfully updated permission for training002\u001b[0m\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Oh, we don't have permission to even view the app. Guess our job permissions\n",
    "# don't extend to the application. Let's be a good neighbor and share our apps\n",
    "# with each other\n",
    "! apps-pems-update -u training002 -p READ \"${AGAVE_USERNAME}-${MACHINE_NAME}-fork-1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0mtraining002 READ WRITE EXECUTE \r\n",
      "ktraxler READ EXECUTE \r\n",
      "training001 READ \u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Now do we have access to the app?\n",
    "! apps-pems-list $SHARED_JOB_APP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0m\u001b[1;0mSuccessfully updated permission for training002\u001b[0m\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Score, but wait, do I need execute to run? We should granb that too.\n",
    "# Hmm, do we have access to the app?\n",
    "! apps-pems-update -u training002 -p EXECUTE \"${AGAVE_USERNAME}-${MACHINE_NAME}-fork-1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0mtraining002 READ WRITE EXECUTE \r\n",
      "ktraxler READ EXECUTE \r\n",
      "training001 READ \u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Now do we have access to the app?\n",
    "! apps-pems-list $SHARED_JOB_APP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0m\u001b[1;0mSuccessfully updated permission for training002\u001b[0m\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# I guess permissions aren't hierachical. Now i can execute it (I think), but I can't\n",
    "# read it. How aabout we grant read_execute instead\n",
    "! apps-pems-update -u training002 -p READ_EXECUTE \"${AGAVE_USERNAME}-${MACHINE_NAME}-fork-1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0mtraining002 READ WRITE EXECUTE \r\n",
      "ktraxler READ EXECUTE \r\n",
      "training001 READ \u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Now do we have access to the app?\n",
    "! apps-pems-list $SHARED_JOB_APP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mPermission denied. You do not have permission to access this app\u001b[0m\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# So now we can rerun our neighbor's job, right\n",
    "!jobs-resubmit -v $SHARED_JOB_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mUser does not have the necessary role to view this system.\u001b[0m\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# drat. why can't we run now? Do we have system access?\n",
    "!systems-roles-list $SHARED_JOB_SYSTEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0mSuccessfully updated roles for user training002 on nectar-exec-training001\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# ok, let's skip to the end. we'll just realize we should grant a user rather than guest role\n",
    "# to the system\n",
    "!systems-roles-addupdate -u training002 -r USER $AGAVE_EXECUTION_SYSTEM_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# that should work, right?\n",
    "!systems-roles-list $SHARED_JOB_SYSTEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So can we run the job now?\n",
    "resubmitted_job_id = ! jobs-resubmit -v --filter=id $SHARED_JOB_ID | jq -r '.id'\n",
    "os.environ['RESUBMITTED_JOB_ID'] = resubmitted_job_id[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4650470882124304871-242ac11b-0001-007\n",
      "\u001b[1;0mtraining001 READ WRITE \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# yay. wait, who owns the data?\n",
    "print (resubmitted_job_id[0])\n",
    "! jobs-pems-list $RESUBMITTED_JOB_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0mSuccessfully stopped job 4650470882124304871-242ac11b-0001-007\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# mine, mine, mine, mine, mine, mine, mine, mine, mine, mine, mine, mine, mine\n",
    "# kill it, we're moving on.\n",
    "! jobs-stop $RESUBMITTED_JOB_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we can also share data a few ways\n",
    "job_output_url = ! jobs-output-list -v --filter=_links $JOB_ID fork-command-1.out | jq -r '.[0]._links.self.href'\n",
    "os.environ['JOB_OUTPUT_URL'] = job_output_url[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "postit_url = ! postits-create -m 3 -l 86400 -V $JOB_OUTPUT_URL | jq -r '.result._links.self.href' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://public.agaveapi.co/postits/v2/422cc513f6cd4b06c0594ca427cc74d6\n"
     ]
    }
   ],
   "source": [
    "# click on the link a few times to see it working.\n",
    "print (postit_url[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0mSuccessfully updated permission for training002\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# you can also share your data via the files api\n",
    "# let's share the job directory with each other\n",
    "job_path = ! jobs-list -v $JOB_ID | jq -r '.outputPath'\n",
    "os.environ['JOB_OUTPUT_FOLDER_PATH'] = job_path[0]\n",
    "! files-pems-update -u training002 -p read -S $AGAVE_EXECUTION_SYSTEM_ID $JOB_OUTPUT_FOLDER_PATH/fork-command-1.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;0mSuccessfully deleted job 6071406585651392025-242ac11b-0001-007\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!jobs-delete $JOB_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the TOGO web portal  \n",
    "\n",
    "Follow the link below to run your job from a web portal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!echo http://togo.solveij.com/app/#/apps/${AGAVE_USERNAME}-${MACHINE_NAME}-fork-1.0/run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
